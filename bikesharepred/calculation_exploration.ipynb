{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis as an\n",
    "import importlib\n",
    "importlib.reload(an)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = an.BikeShareData.load_from_pickle(name = '2024-5')\n",
    "\n",
    "avg_lat = np.mean(data.stations['lat'])\n",
    "avg_lon = np.mean(data.stations['lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "\n",
    "__geod = pyproj.Geod(ellps='WGS84')\n",
    "def dst(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the distance between two points on the Earth's surface in meters.\n",
    "    \"\"\"\n",
    "    angle1,angle2,distance = __geod.inv(lon1, lat1, lon2, lat2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node degree: min 2.0, max 16.0, mean 3.8776470588235292, std 2.9931834900059653\n",
      "Dst shape: (850, 850)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# calculate adjacency matrix for the station distance graph\n",
    "# the station graph \n",
    "max_dst = 500 # meters\n",
    "min_stations_connected = 2 # should always be connected to at least min_stations_connected other stations\n",
    "\n",
    "# remove stations with missing lat/lon\n",
    "# after having eliminated ghost stations (missing lat/lon), we have a new sequential index\n",
    "stations = data.stations[~(data.stations['lat'].isna() | data.stations['lon'].isna())]\n",
    "# thus we have new_index < old_index\n",
    "new2old_idx = np.array([old_idx for old_idx in stations.index])\n",
    "stations = stations.reset_index(drop=True)\n",
    "\n",
    "# connect stations that are within max_dst of each other; or connect the closest stations until min_stations_connected is reached ; additionally add self-loops\n",
    "\n",
    "adj = np.zeros((len(stations), len(stations)))\n",
    "lats, lons = np.array(stations['lat']), np.array(stations['lon'])\n",
    "dst_matrix = np.zeros_like(adj, dtype=np.float32)\n",
    "N_stations = len(stations)\n",
    "for i in range(len(stations)):\n",
    "    dst_matrix[i, :] = dst(np.tile(lats[i], N_stations), np.tile(lons[i], N_stations), lats, lons)\n",
    "\n",
    "# adj = adj + adj.T + np.eye(len(stations)) # add self-loops\n",
    "adj[dst_matrix < max_dst] = 1\n",
    "for i in range(len(stations)):\n",
    "    if np.sum(adj[i, :]) < min_stations_connected * 2 + 1: # node degree is (sum of row i - 1) // 2 (we exclude the self-loop)\n",
    "        # connect the closest stations\n",
    "        closest = np.argsort(dst_matrix[i, :])\n",
    "        for j in range(2 * min_stations_connected + 1):\n",
    "            adj[i, closest[j]] = 1\n",
    "\n",
    "# test that at least min_stations are connected\n",
    "assert np.all(np.sum(adj, axis=1) >= min_stations_connected)\n",
    "# calculate node degree params\n",
    "node_degrees = (np.sum(adj, axis=1) - 1) // 2\n",
    "print(f\"Node degree: min {np.min(node_degrees)}, max {np.max(node_degrees)}, mean {np.mean(node_degrees)}, std {np.std(node_degrees)}\")\n",
    "\n",
    "print(\"Dst shape:\", dst_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 3],\n",
       "       [0, 3, 3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mat = np.random.randint(0, 2, (5, 5))\n",
    "mat = (mat + mat.T + np.eye(5)) // 2\n",
    "print(mat)\n",
    "inds_i, inds_j = mat.nonzero()\n",
    "list(zip(inds_i, inds_j))\n",
    "\n",
    "adj = mat.copy()\n",
    "adj[np.tril_indices(adj.shape[0], k= -1)] = 0 # zero out the strict lower triangle (starting at diagonal -1 to the right) to not count edges twice\n",
    "inds_i, inds_j = np.nonzero(adj)\n",
    "num_edges = len(inds_i)\n",
    "np.stack([inds_i, inds_j], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'train_test_split' from 'sklearn.utils' (/mnt/vol2/BikeSharePrediction/.venv/lib/python3.12/site-packages/sklearn/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install scikit-learn\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# select train, eval and test days randomly from the month\u001b[39;00m\n\u001b[1;32m      4\u001b[0m N_days \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'train_test_split' from 'sklearn.utils' (/mnt/vol2/BikeSharePrediction/.venv/lib/python3.12/site-packages/sklearn/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn\n",
    "import sklearn.utils\n",
    "#td: select train, eval and test days randomly from the month\n",
    "N_days = 30\n",
    "train_days = range(0,24)\n",
    "eval_days = range(24, 28)\n",
    "test_days = range(28, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A data object describing a homogeneous graph.\n",
      "    The data object can hold node-level, link-level and graph-level attributes.\n",
      "    In general, :class:`~torch_geometric.data.Data` tries to mimic the\n",
      "    behavior of a regular :python:`Python` dictionary.\n",
      "    In addition, it provides useful functionality for analyzing graph\n",
      "    structures, and provides basic PyTorch tensor functionalities.\n",
      "    See `here <https://pytorch-geometric.readthedocs.io/en/latest/get_started/\n",
      "    introduction.html#data-handling-of-graphs>`__ for the accompanying\n",
      "    tutorial.\n",
      "\n",
      "    .. code-block:: python\n",
      "\n",
      "        from torch_geometric.data import Data\n",
      "\n",
      "        data = Data(x=x, edge_index=edge_index, ...)\n",
      "\n",
      "        # Add additional arguments to `data`:\n",
      "        data.train_idx = torch.tensor([...], dtype=torch.long)\n",
      "        data.test_mask = torch.tensor([...], dtype=torch.bool)\n",
      "\n",
      "        # Analyzing the graph structure:\n",
      "        data.num_nodes\n",
      "        >>> 23\n",
      "\n",
      "        data.is_directed()\n",
      "        >>> False\n",
      "\n",
      "        # PyTorch tensor functionality:\n",
      "        data = data.pin_memory()\n",
      "        data = data.to('cuda:0', non_blocking=True)\n",
      "\n",
      "    Args:\n",
      "        x (torch.Tensor, optional): Node feature matrix with shape\n",
      "            :obj:`[num_nodes, num_node_features]`. (default: :obj:`None`)\n",
      "        edge_index (LongTensor, optional): Graph connectivity in COO format\n",
      "            with shape :obj:`[2, num_edges]`. (default: :obj:`None`)\n",
      "        edge_attr (torch.Tensor, optional): Edge feature matrix with shape\n",
      "            :obj:`[num_edges, num_edge_features]`. (default: :obj:`None`)\n",
      "        y (torch.Tensor, optional): Graph-level or node-level ground-truth\n",
      "            labels with arbitrary shape. (default: :obj:`None`)\n",
      "        pos (torch.Tensor, optional): Node position matrix with shape\n",
      "            :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)\n",
      "        time (torch.Tensor, optional): The timestamps for each event with shape\n",
      "            :obj:`[num_edges]` or :obj:`[num_nodes]`. (default: :obj:`None`)\n",
      "        **kwargs (optional): Additional attributes.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(850, 83083)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.data as geomdata\n",
    "\n",
    "cfg = {'N_pred': 12, 'N_hist' : 12} \n",
    "n_window = cfg['N_hist'] + cfg['N_pred']\n",
    "sequences = []\n",
    "\n",
    "graphdata = geomdata.Data()\n",
    "# data.x : source ; dimensions N × F\n",
    "# data.y : pred ; dimensions N × Predicted ; here, we do N × History × FeatureLen (FeatureLen = 2 (In rates, out rates))\n",
    "in_rates = data.in_rates[new2old_idx, 0::5] # only retrieve the real station data , and only take it all five minutes\n",
    "# iterate the window over the whole data\n",
    "\n",
    "print(geomdata.Data.__doc__)\n",
    "in_rates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/vol2/BikeSharePrediction/src'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path(os.getcwd())\n",
    "cwd.parents[0], cwd.parents[1]\n",
    "str(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.06e-10\n"
     ]
    }
   ],
   "source": [
    "print(f\"{2.058e-10:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "spec not found for the module 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrun_training\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m overfit_config\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/importlib/__init__.py:130\u001b[0m, in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    128\u001b[0m spec \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m__spec__ \u001b[38;5;241m=\u001b[39m _bootstrap\u001b[38;5;241m.\u001b[39m_find_spec(name, pkgpath, target)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec not found for the module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    131\u001b[0m _bootstrap\u001b[38;5;241m.\u001b[39m_exec(spec, module)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# The module may have replaced itself in sys.modules!\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: spec not found for the module 'dataset'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import dataset\n",
    "from run_training import overfit_config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cfg = overfit_config()\n",
    "data = dataset.BikeGraphDataset(cfg)\n",
    "model = \n",
    "\n",
    "# plot the first sample\n",
    "sample = data[0]\n",
    "print(\"Shapes:\" ,sample['x'].shape, sample['y'].shape)\n",
    "y = sample['y'].view(cfg['N_stations'], cfg['N_predictions'], 2)\n",
    "station = 0\n",
    "# interpolate the y data with cubic splines\n",
    "\n",
    "\n",
    "plt.plot(y[station, :, 0].numpy(), label='In Rates')\n",
    "plt.plot(y[station, :, 1].numpy(), label='Out Rates')\n",
    "# set axis to 5 minutes at each sample\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(0, cfg['N_predictions']), np.arange(0, cfg['N_predictions'] * cfg['subsample_minutes'], cfg['subsample_minutes']))\n",
    "plt.gca().set(xlabel='Time (minutes)', ylabel='Rate (bikes/min)', title='In Rates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
